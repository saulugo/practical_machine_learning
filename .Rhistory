x
set.sed(0)
set.seed(0)
x <- rnorm(9,mean=1100,sd=30)
x
x <- rnorm(9,mean=1100,sd=30)
x
?t.test
t.test(x,alternative="two.sided",mu=1100,conf.level=0.95)
1100 + c(-1,1)*qnorm(.975)*10
round(1100 + c(-1,1)*qnorm(.975)*10,1)
round(1100 + c(-1,1)*qnorm(.975)*10,0)
pbinom(2,size=4,prob=0.5,lower.tail=FALSE)
ppois((1000/1787),lambda=(1/100),lower.tail=TRUE)
ppois((1000/1787),lambda=(1/100),lower.tail=FALSE)
round(ppois((1000/1787),lambda=(1/100),lower.tail=FALSE),2)
ppois((1000/1787),1,lower.tail=FALSE)
ppois((1000/1787),1,lower.tail=TRUE)
qnorm(.95)
round(qnorm(.95),2
)
power.t.test(n=160,delta=0.01,sd=0.04,alt="one.sided")
power.t.test(n=160,delta=0.01,sd=0.04,alt="one.sided")$power
power.t.test(n=160,delta=0.01,sd=0.04,alt="one.sided")$power*100
round(power.t.test(n=160,delta=0.01,sd=0.04,alt="one.sided")$power*100,1)
round(power.t.test(n=180,delta=0.01,sd=0.04,alt="one.sided")$power*100,1)
round(power.t.test(n=120,delta=0.01,sd=0.04,alt="one.sided")$power*100,1)
round(power.t.test(n=140,delta=0.01,sd=0.04,alt="one.sided")$power*100,1)
round(power.t.test(n=140,delta=0.01,sd=0.04,type="one.sample",alt="one.sided")$power*100,1)
round(power.t.test(n=160,delta=0.01,sd=0.04,type="one.sample",alt="one.sided")$power*100,1)
round(power.t.test(n=160,delta=0.01,sd=0.04,type="one.sample",alt="one.sided")$power*100,0)
round(power.t.test(n=180,delta=0.01,sd=0.04,type="one.sample",alt="one.sided")$power*100,0)
round(power.t.test(n=120,delta=0.01,sd=0.04,type="one.sample",alt="one.sided")$power*100,0)
round(power.t.test(n=140,delta=0.01,sd=0.04,type="one.sample",alt="one.sided")$power*100,0)
round(power.t.test(n=100,delta=0.01,sd=0.04,type="one.sample",alt="one.sided")$power*100,0)
round(power.t.test(n=100,delta=0.01,sd=0.04,type="one.sample",alt="one.sided")$power,0)
round(power.t.test(n=100,delta=0.01,sd=0.04,type="one.sample",alt="one.sided")$power,2)
setwd("~/Coursera/data_science/machine_learning")
install.packages("caret")
install.packages("ISLR")
library(ISLR)
library(caret)
library(ggplot2)
data(Wage)
head(Wage)
?Wage
summary(Wage)
inTrain <- createDataPartition(y = Wage$wage, p = 0.7, list = FALSE)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
dim(training); dim(testing)
dim(training)
dim(testing)
2102/(2102+898)
featurePlot(x = training[,c("age", "education", "jobclass")], y = training$wage, plot="pairs")
qplot
qplot(age, wate, data=training)
qplot(age, wage, data=training)
qplot(age, wage, colour = jobclass,data=training)
head(Wage)
qplot(age, wage, colour = education,data=training)
qplot(age, wage, colour = health,data=training)
qplot(age, wage, colour = race,data=training)
qplot(age, wage, colour = naritl,data=training)
qplot(age, wage, colour = maritl,data=training)
qq <- qplot(age, wage, colour=education, data=training)
qq + geom_smooth(method="lm", formula = y ~ x)
library(Hmisc)
cutWage <- cut2(training$wage, g=3)
table(cutWage)
p1 <- qplot(cutWage, age, data=training, fill=cutWage, geom = c("boxplot"))
p1
p2 <- qplot(cutWage, age, data = training, fill = cutWage, geom = c("boxplot","jitter"))
grid.arrange(p1, p2, ncol=2)
?grid.arrange
library(grid)
p2 <- qplot(cutWage, age, data = training, fill = cutWage, geom = c("boxplot","jitter"))
grid.arrange(p1, p2, ncol=2)
?grid.a
??grid.a
p2
t1 <- table(cutWage,training$jobclass)
t1
t1 <- table(cutWage,training$race)
t1 <- table(cutWage,training$jobclass)
t2 <- table(cutWage,training$race)
t2
t3 <- table(cutWage,training$education)
t3
t1 <- table(cutWage,training$jobclass)
prop.table(t2,1)
qplot(wage colour=education, data=training, geom="density")
qplot(wage, colour=education, data=training, geom="density")
summary(training)
dim(training)
hist(training$capitalAve)
summary(training)
library(caret)
library(kernlab)
data(spam)
inTrain <- createDataPartition(y=span$type, p=0.75, list=FALSE)
inTrain <- createDataPartition(y=spam$type, p=0.75, list=FALSE)
training <- spam[inTrain]
test <- spam[-inTrain]
hist(spam$capitalAve,main="Capital in a Row in the emails of the dataset",xlab="ave. capital run length")
mean(spam$capitalAve)
mean(training$capitalAve)
hist(training$capitalAve,main="Capital in a Row in the emails of the dataset",xlab="ave. capital run length")
summary(training)
test <- spam[-inTrain,]
training <- spam[inTrain,]
hist(training$capitalAve,main="Capital in a Row in the emails of the dataset",xlab="ave. capital run length")
mean(training$capitalAve)
sd(training$capitalAve)
trainCapAve <- training$capitalAve
tranCapAveS <- (trainCapAve - mean(trainCapAve))/sd(trainCapAve)
trainCapAveS <- (trainCapAve - mean(trainCapAve))/sd(trainCapAve)
round(trainCapAveS,4)
round(mean(trainCapAveS),4)
round(sd(trainCapAveS),4)
?set.seed
?train
install.packages('caret', dependencies = TRUE)
install.packages("caret", dependencies = TRUE)
rbinom(10,size=1,prob=0.05)
rbinom(10,size=1,prob=0.5)
rbinom(100,size=1,prob=0.05)
?prComp
?prcomp
library(caret)
library(kernlab)
data(spam)
inTrain <- createDataPartition(y=spam$type, p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
typeColor <- ((spam$type=="spam")*1 + 1)
typeColor
typeColor <- ((spam$type=="spam")*1 + 1) #clasifies each point for coloring as spam or ham
prComp <- prcomp(log10(spam[,-58]+1)) #the log10 is to make the variables look more "normal"
plot(prComp$x[,1],prComp$x[,2],col=typeColor,xlab="PC1",ylab="PC2")
prComp
names(spam)
prComp
cor(spam$name,spam$type)
summary(spam$name)
summary(spam$make)
cor(spam$make,spam$type)
summary(spam$type)
spam$mytype <- ifelse(spam$type=="nonspam",0,1)
summary(spam$mytype)
sum(spam$mytype)
cor(spam$make,spam$mytype)
preProc <- preProcess(log10(spam[,-58])+1),method="pca",pcaComp=2)
spamPC <- predict(preProc,log10(spam[,-58])+1))
plot(spamPC[,1],spamPC[,2],col=typeColor)
preProc <- preProcess(log10(spam[,-58])+1),method="pca",pcaComp=2)
preProc <- preProcess(log10(spam[,-58]+1),method="pca",pcaComp=2)
spamPC <- predict(preProc,log10(spam[,-58])+1))
plot(spamPC[,1],spamPC[,2],col=typeColor)
preProc <- preProcess(log10(spam[,-58]+1),method="pca",pcaComp=2)
spamPC <- predict(preProc,log10(spam[,-58]+1))
plot(spamPC[,1],spamPC[,2],col=typeColor)
trainPC <- predict(preProc,log10(training[,-58]+1))
modelFit <- train(training$type ~ .,method="glm",data=trainPC)
trainPC <- predict(preProc,log10(training[,-58]+1))
head(training)
trainPC <- predict(preProc,log10(training[,-58]+1))
summary(preProc)
preProc <- preProcess(log10(training[,-58]+1),method="pca",pcaComp=2)
trainPC <- predict(preProc,log10(training[,-58]+1))
modelFit <- train(training$type ~ .,method="glm",data=trainPC)
warnings()
modelFit
modelFit
confusionMatrix(training$type,predict(modelFit,trainPC))
testPC <- predict(preProc,log10(testing[,-58]+1)) #one must use the same preProc obj calculated for the training
confusionMatrix(testing$type,predict(modelFit,testPC)) #one must also use the same model fitted for the trining
modelFit <- train(training$type ~ .,method="glm",preProcess="pca",data=training)
confusionMatrix(training$type,predict(modelFit,training))
confusionMatrix(testing$type,predict(modelFit,testing))
data(faithful); set.seed(333)
inTrain <- createDataPartition(y=faithful$eruptions, p=0.5, list=FALSE)
trainFaith <- faithful[inTrain,]; testFaith <- faithfull[-inTrain,]
head(trainFaith)
modFit <- train(eruptions ~ waiting,data=trainFaith,method="lm")
summary(modFit$finalModel)
plot(trainFaith$waiting,trainFaith$eruptions)
lines(trainFaith$waiting,modFit$finalModel$fitted,col="blue")
library(ISLR); library(ggplot2); library(caret)
data(Wage); Wage <- subset(Wage,select=-c(logwage))
summary(Wage)
#Splitting the data
inTrain <- createDataPartition(y=Wage$wage,p=0.7,list=FALSE)
training <- Wage[inTrain,]; testing <- Wage[-inTrain,]
dim(training); dim(testing)
modFit <- train(wage ~ age + jobclass + education, method="lm", data=training) #we fit the model on the training data
fitMod <- modFit$finalModel
print(modFit)
plot(fitMod,1,pch=19,cex=0.5,col="#00000010")
fitMod
qplot(fitMod$fitted, fitMod$residuals, colour=race, data=training)
plot(fitMod$residuals,pch=19)
pred <- predict(modFit, testing)
qplot(wage, pred, colour=year,data=testing)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
head(AlzheimerDisease)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
head(AlzheimerDisease)
?AlzheimerDisease
?AppliedPredictiveModeling
data(concrete)
head(concrete)
mixtures
head(concrete)
head(mixtures)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(training)
qplot(mixtures$CompressiveStrength)
?qplot
qplot(1:nrow(mixtures),mixtures$CompressiveStrength)
?cut2
library(Hmisc)
?cut2
x <- c(1,2,3,4,5,6,7,8,9,10)
cut2(x,c(25,50,75))
cut2(x,g=4)
head(mixtures)
summary(mixtures)
cut2(x,g=4)
y <- cut2(x,g=4)
x
y
mixtures$Cement
summary(mixtures)
summary(mixtures$Cement)
cut2(mixtures$Cement,q=3)
cut2(mixtures$Cement,g=3)
head(mixtures)
mixtures$CementInt <- cut2(mixtures$Cement,g=3)
head(mixtures)
x <- 1:nrow(mixtures)
qplot(x,CompressiveStrength,colour=CementInt,data=mixtures)
mixtures$BlastFurnaceSlagInt <- cut2(mixtures$BlastFurnaceSlag,g=3)
qplot(x,CompressiveStrength,colour=BlastFurnaceSlagInt,data=mixtures)
mixtures$FlyAsh <- cut2(mixtures$FlyAshInt,g=3)
summary(mixtures$FlyAsh)
mixtures$FlyAsh
head(mixtures)
mixtures$FlyAshInt <- cut2(mixtures$FlyAsh,g=3)
mixtures$WaterInt <- cut2(mixtures$Water,g=3)
mixtures$SuperplasticizerInt <- cut2(mixtures$Superplasticizer,g=3)
mixtures$CoarseAggregateInt <- cut2(mixtures$CoarseAggregate,g=3)
mixtures$CoarseFineAggregateInt <- cut2(mixtures$FineAggregate,g=3)
mixtures$AgeInt <- cut2(mixtures$Age,g=4)
head(mixtures)
qplot(x,CompressiveStrength,colour=CementInt,data=mixtures)
?mfrow
par(mfrow=c(2,4))
qplot(x,CompressiveStrength,colour=CementInt,data=mixtures)
qplot(x,CompressiveStrength,colour=BlastFurnaceSlagInt,data=mixtures)
par(mfrow=c(2,4))
qplot(x,CompressiveStrength,colour=CementInt,data=mixtures)
qplot(x,CompressiveStrength,colour=BlastFurnaceSlagInt,data=mixtures)
qplot(x,CompressiveStrength,colour=FlyAshInt,data=mixtures)
qplot(x,CompressiveStrength,colour=WaterInt,data=mixtures)
qplot(x,CompressiveStrength,colour=SuperplasticizerInt,data=mixtures)
qplot(x,CompressiveStrength,colour=CoarseAggregateInt,data=mixtures)
qplot(x,CompressiveStrength,colour=AgeInt,data=mixtures)
qplot(x,CompressiveStrength,colour=FlyAshInt,data=mixtures)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(mixtures)
hist(mixtures$Superplasticizer)
mean(mixtures$Superplasticizer)
sd(mixtures$Superplasticizer)
sumary(mixtures$Superplasticizer)
summary(mixtures$Superplasticizer)
hist(log10(mixtures$Superplasticizer+1))
hist(mixtures$Superplasticizer)
hist(log10(mixtures$Superplasticizer+1))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
head(adData)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names(training)
?grepl
grepl("ul","saul")
grepl("ulx","saul")
myvar <- grepl("IL",names(training))
myvar
myvar * names(training)
myvar <- ifelse(TRUE,1,0)
myvar
myvar <- grepl("IL",names(training))
myvar
myvar <- ifelse(myvar==TRUE,1,0)
myvar
regexpr("sa","saul")
grepexpr("sa","saul")
gregexpr("sa","saul")
regexpr("sa","saul")
regexpr("saa","saul")
regexpr("xxx","saul")
regexpr("ul","saul")
regexpr("ul","saul")[1]
regexpr("sa","saul")[1]
regexpr("sa","saul sa")[1]
regexpr("sa","aul sa")[1]
myvar <- ifelse(regexpr("IL",names(training))[1]==1,names(training),0)
myvar
myvar <- ifelse(regexpr("IL",names(training))[1]==1,1,0)
myvar
myvar <- regexpr("IL",names(training))[1]
myvar
head(training)
names(training)
myvar <- grepl("IL",names(training))
myvar
regexpr("sa","saul")
regexpr("ss","saul")
myvar <- regexpr("IL",names(training))
myvar
res <- c()
res <- cbind(res,"x")
res
x <- c(1,2,3)
x
res <- null
res <- NULL
res <- res + 1
res
res <- NULL
res <- res + c("a")
res <- vector("character",length=0)
res
res <- res + c("a","b","c")
grep("s","saul")
grep("a","saul")
grep("x","saul")
grep("a","sula")
grep("^[a]","sula")
grep("^[a]","asula")
grep("^[IL]","IL_asula")
grep("^[IL]","Ias_IL_ula")
grep("^IL","Ias_IL_ula")
grep("^IL","ILas_IL_ula")
grep("^IL","Las_IL_ula")
mytrain <- training[,grep("^IL",names(training), value=TRUE)]
head(mytrain)
hist(mytrain$IL_7)
hist(mytrain$IL_11)
hist(log10(mytrain$IL_11+1))
hist(mytrain$IL_11)
hist(mytrain$IL_13)
hist(mytrain$IL_16)
hist(mytrain$IL_17E)
names(mytrain)
length(names(mytrain))
preProc <- preProcess(mytrain,method="pca",pcaComp=12)
trainPC <- predict(preProc,mytrain)
preProc
print(preProc)
names(training)
summary(train$diagnosis)
summary(training$diagnosis)
trainPC <- predict(preProc,mytrain)
head(trainPC)
modelFit <- train(training$diagnosis ~ .,method="glm",data=trainPC)
modelFit
confusionMatrix(training$diagnosis,predict(modelFit,trainPC))
preProc <- preProcess(mytrain,method="pca")
summary(preProc)
preProc
preProc <- preProcess(mytrain,method="pca",pcaComp=10)
preProc
summary(preProc)
preProc
preProc <- preProcess(mytrain,method="pca")
preProc
preProc <- preProcess(mytrain,method="pca",thresh=80)
preProc
preProc <- preProcess(mytrain,method="pca",thresh=.8)
preProc
head(mytrain)
mytrain$diagnosis <- training$diagnosis
head(mytrain)
fit1 <- train(diagnosis ~ .,method="glm",data=mytrain)
fit1
testPre1 <- predict(fit1,testing[,-1])
confusionMatrix(testing$diagnosis,predict(fit1,testing[,-1]))
fit2 <- train(mytrain$diagnosis ~ .,method="glm",preProcess="pca",data=mytraining,thresh=80)
fit2 <- train(mytrain$diagnosis ~ .,method="glm",preProcess="pca",data=mytrain,thresh=80)
preProc
trainPC <- predict(preProc,mytrain[,-1])
head(mytrain)
head(mytrain[,-13])
trainPC <- predict(preProc,mytrain[,-13])
fit2 <- train(mytrain$diagnosis ~ .,method="glm",data=trainPC)
names(testing)
testPC <- predict(preProc,testing[,-1])
confusionMatrix(testing$diagnosis,predict(fit2,testPC))
fit1
confusionMatrix(testing$diagnosis,predict(fit1,testing[,-1]))
confusionMatrix(testing$diagnosis,predict(fit2,testPC))
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictions)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.5)
training = adData[trainIndex,]
trainIndex = createDataPartition(diagnosis, p = 0.5,list=FALSE)
training = adData[trainIndex,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
mytrain <- training[,grep("^IL",names(training), value=TRUE)]
head(mytrain)
preProc <- preProcess(mytrain,method="pca",thresh=.8)
preProc
preProc <- preProcess(mytrain,method="pca",thresh=.9)
preProc
mytrain$diagnosis <- training$diagnosis
fit1 <- train(diagnosis ~.,method="glm",data=mytrain)
confusionMatrix(testing$diagnosis,predict(fit1,testing[,-1]))
preProc <- preProcess(mytrain,method="pca",thresh=.8)
preProc
trainPC <- predict(preProc,mytrain[,-13])
names(mytrain[,-13])
fit2 <- train(mytrain$diagnosis ~ .,method="glm",data=trainPC)
testPC <- predict(preProc,testing[,-1])
confusionMatrix(testing$diagnosis,predict(fit2,testPC))
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$Superplasticizer)
hist(log10(training$Superplasticizer))
hist(training$Superplasticizer)
summary(training$Superplasticizer)
hist(log10(training$Superplasticizer+1))
hist(log10(training$Superplasticizer))
summary(training$Superplasticizer)
hist(log10(training$Superplasticizer))
hist(log10(training$Superplasticizer))
hist(training$Superplasticizer)
hist(training$Superplasticizer+1)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis, p=0.5, list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
dim(training)
dim(testing)
dim(adData)
length(names(adDAta))
length(names(adData))
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p=0.5, list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex]
dim(adData)
dim(training)
dim(testing)
testing = adData[-trainIndex,]
dim(testing)
